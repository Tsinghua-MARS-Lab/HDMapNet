<!doctype html>
<html lang="en">

<!-- === Header Starts === -->
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>HDMapNet</title>

    <link href="./assets/bootstrap.min.css" rel="stylesheet">
    <link href="./css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <!-- <link href="./assets/font.css" rel="stylesheet" type="text/css"> -->
    <link href="./assets/style.css" rel="stylesheet" type="text/css">

    <script src="./assets/jquery.min.js"></script>
    <script type="text/javascript" src="assets/corpus.js"></script>

</head>
<!-- === Header Ends === -->

<script>
    var lang_flag = 1;
</script>

<body>

<!-- === Home Section Starts === -->
<div class="section">
    <!-- === Title Starts === -->

    <!-- <div class="logo" style="padding-left: 120pt" align="top">
        <a href="https://github.com/metadriverse/metadrive" target="_blank">
            <img style=" width: 450pt;" src="images/metadrive.png">
        </a>
    </div> -->

    <div class="header">
        <div style="" class="title" id="lang">
            <b>HDMapNet</b>: An Online HD Map Construction and Evaluation Framework
        </div>
    </div>
    <!-- === Title Ends === -->

    <div class="author" style="margin-top: -10pt">
        <a href="https://liqi17thu.github.io/">Qi Li</a><sup>1</sup>,&nbsp;
        <a href="https://people.csail.mit.edu/yuewang/" target="_blank">Yue Wang</a><sup>2</sup>,&nbsp;
        <a href="https://scholar.google.com.hk/citations?hl=en&user=nUyTDosAAAAJ">Yilun Wang</a><sup>3</sup>,&nbsp;
        <a href="https://hangzhaomit.github.io/">Hang Zhao</a><sup>1</sup>&nbsp;
    </div>

    <div class="institution">
        <div><sup>1</sup>Tsinghua University,
            <sup>2</sup>MIT,
            <sup>3</sup>Li Auto
        </div>

        <!-- <div class="social-icons">
            <a href="https://arxiv.org/abs/2107.06307/">
                <i class="fas fab fa-sticky-note"></i>ICRA 2022 (long version)
            </a>
            &nbsp;&nbsp;&nbsp;
            <a href="https://drive.google.com/file/d/1CEX232SJIUDTPPIviSM_K47QkhV9_5ua/view">
                <i class="fas fab fa-sticky-note"></i>CVPR 2021 Workshop (best paper nominee)
            </a>
            &nbsp;&nbsp;&nbsp;
            <a href="https://github.com/Tsinghua-MARS-Lab/HDMapNet">
                <i class="fab fab fa-github"></i>Code
            </a>
        </div> -->

    </div>

<!-- 
    <table border="0" align="center">
        <tr>
            <td align="center" style="padding: 0pt 0 15pt 0">
                <a class="bar" href="https://arxiv.org/abs/2107.06307/"><b>ICRA 2022 (long version)</b></a> |
                <a class="bar" href="https://drive.google.com/file/d/1CEX232SJIUDTPPIviSM_K47QkhV9_5ua/view"><b>CVPR 2021 Workshop (best paper nominee)</b></a> |
                <a class="bar" href="https://github.com/Tsinghua-MARS-Lab/HDMapNet"><b>Code</b></a>
            </td>
        </tr>
    </table>
    
 -->    
</div>
<!-- === Home Section Ends === -->


<div class="section">
    <div class="title" id="lang">Demos</div>
    
    <div class="col">
        <table width="100%" style="margin: 0pt 0pt; text-align: left;">
        <tr>
            <td><img src="images/scene0_car_small.gif" style="max-width: 90%;"></td>
            <td><img src="images/scene2_car_small.gif" style="max-width: 90%;"></td>
            <td><img src="images/scene3_car_small.gif" style="max-width: 90%;"></td>
        </tr>
        <tr  height="10"></tr>
        <tr>
            <td><img src="images/scene5_car_small.gif" style="max-width: 90%;"></td>
            <td><img src="images/scene13_car_small.gif" style="max-width: 90%;"></td>
            <td><img src="images/scene14_car_small.gif" style="max-width: 90%;"></td>
        </tr>
        </table>
    </div>
    <p>
        The vectorized HD Map predicted by HDMapNet. The red lines indicate lane boundary, the white ones indicate lane divider, and the yellow ones indicate ped crossing. We draw LiDAR point clouds over the map for visualization purpose.
    </p>

</div>


<div class="section">
    <div class="title" id="lang">Temporal Map Construction</div>
        <div class="col">
        <table width="100%" style="margin: 0pt 0pt; text-align: left;">
        <tr>
            <td><img src="images/temporal_12_small.gif" style="max-width: 95%;"></td>
            <td><img src="images/temporal_14_small.gif" style="max-width: 95%;"></td>
        </tr>
        <tr>
            <td><img src="images/temporal_89_small.gif" style="max-width: 90%;"></td>
            <td><img src="images/temporal_118_small.gif" style="max-width: 90%;"></td>
        </tr>
        <tr>
            <td><img src="images/temporal_148_small.gif" style="max-width: 90%;"></td>
            <td><img src="images/temporal_43_small.gif" style="max-width: 90%;"></td>
        </tr>
        </table>
    </div>
    <p>
        Long-term temporal accumulation by pasting feature maps of previous frames into current's according to ego poses. The feature maps are fused by max pooling and then fed into decoder.
    </p>
</div>

<div class="section">
    <div class="title" id="lang">Main Idea</div>
    <img src="images/teaser_v3.png" style="max-width: 100%;">
    <p>
        <b>Main idea</b>. High-definition map (HD map) construction is a crucial problem for autonomous driving. This problem typically involves collecting high-quality point clouds, fusing multiple point clouds of the same scene, annotating map elements, and updating maps constantly. This pipeline, however, requires a vast amount of human efforts and resources which limits its scalability. In this paper, we argue that online map learning, which dynamically constructs the HD maps based on local sensor observations, is a more scalable way to provide semantic and geometry priors to self-driving vehicles than traditional pre-annotated HD maps. We introduce a strong online map learning method, titled HDMapNet.
    </p>
</div>

<div class="section">
    <div class="title" id="lang">Method</div>
    <div class="logo" style="" align="center">
        <img style="max-width: 100%;" src="images/overview_v3.png">
    </div>
    <p>
        <b>The overview of HDMapNet</b>. Four neural network parameterize our model: a perspective view image encoder, a neural view transformer in image branch, a pillar-based point cloud encoder, and a map element decoder. The output of the map decoder has 3 branches: semantic segmentation, instance detection and direction classification, which are processed into vectorized HD map. 
    </p>    
</div>


<div class="section">
    <div class="title" id="lang">More Results</div>
    <div class="logo" style="" align="center">
        <video controls preload="auto" width="100%"  autoplay loop playsinline class="html-video">
            <source src="home/direction_3_car_short_small.mp4" type="video/mp4">
            <p>Your browser doesn't support embedded videos, but don't worry, you can <a href="/HDMapNet/home/direction_3_car_short_small.mp4">download it</a> and watch it with your favorite video player!</p>
        </video>
    </div>
    <p>
        The left part is the corresonding 6 images, the right one is the HD map prediction. We align the LiDAR point clouds on it for visualization purpose.
    </p>

    <br>
    <div class="logo" style="" align="center">
        <img style="max-width: 100%;" src="images/qualitative.png">
    </div>
    <p>
        <b>The qualitative results on nuScenes dataset.</b> Top Left: we show the surrounding images and the ground-truth local HD Map annotations. IPM: we show the lane segmentation result in the perspective view and in the bird's-eye view. Others: we show the semantic segmentation results and the vectorized instance detection results. As we can see, Our HDMapNet(Surr) and HDMapNet(Fusion) outputs are close to the ground-truth HD Map and the fusion based HDMapNet is clearly the best.
    </p> 
</div>

<div class="section">
    <div class="title" id="lang">Talk</div>
    <div class="logo" style="" align="center">
       <iframe src="https://www.youtube.com/embed/AJ-rToTN8y8" style="max-width: 90%;" allowfullscreen title="YouTube Video"></iframe>
    </div>
</div>

<div class="section">
    <div class="title" id="lang">Related Projects on VCAD (Vision-Centric Autonomous Driving)</div>
    <div class="col text-center">

    <table width="100%" style="margin: 0pt 0pt; text-align: center;">
    <tr>
      <td>
        <a href="#" class="d-inline-block p-3"><img height="100"
          src="images/MUTR3D_paper_thumbnail.png" style="border:1px solid"
          data-nothumb><br>DETR3D</a>
      </td>
      <td>
        <a href="#" class="d-inline-block p-3"><img height="100"
          src="images/MUTR3D_paper_thumbnail.png" style="border:1px solid"
          data-nothumb><br>MUTR3D</a>
      </td>
      <td>
      <a href="#" class="d-inline-block p-3"><img height="100"
          src="images/MUTR3D_paper_thumbnail.png" style="border:1px solid"
          data-nothumb><br>FUTR3D</a>
      </td>

    </tr>
    </table>
    </div>
</div>

<!-- === Reference Section Starts === -->
<div class="section">
    <div class="bibtex">
       <div class="title" id="lang">Reference</div>
    </div>

<p>If you find our work useful in your research, please cite our paper:</p>
<pre>
@article{li2021hdmapnet,
  title={HDMapNet: An Online HD Map Construction and Evaluation Framework},
  author={Qi Li and Yue Wang and Yilun Wang and Hang Zhao},
  journal={arXiv preprint arXiv:2107.06307},
  year={2021}
}
</pre>
    <!-- Adjust the frame size based on the demo (Every project differs). -->
</div>

</body>
</html>
